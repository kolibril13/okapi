{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import bpy\n",
    "#from bl_ext.blender_org.csv_importer import PolarsMesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://github.com/BradyAJohnston/MolecularNodes/blob/80f3dac339750638bb5f5edc3b1e66292fccf642/molecularnodes/bpyd/attribute.py\n",
    "# and this prompt: https://chatgpt.com/share/672de0c6-b18c-8013-84d1-ecf23043c790\n",
    "\n",
    "import bpy\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from dataclasses import dataclass\n",
    "from typing import Type, Any\n",
    "from enum import Enum\n",
    "\n",
    "class DomainType(Enum):\n",
    "    POINT = \"POINT\"\n",
    "    EDGE = \"EDGE\"\n",
    "    FACE = \"FACE\"\n",
    "    CORNER = \"CORNER\"\n",
    "    CURVE = \"CURVE\"\n",
    "    INSTANCE = \"INSTANCE\"\n",
    "    LAYER = \"LAYER\"\n",
    "\n",
    "class Domains:\n",
    "    POINT = DomainType.POINT\n",
    "    EDGE = DomainType.EDGE\n",
    "    FACE = DomainType.FACE\n",
    "    CORNER = DomainType.CORNER\n",
    "    CURVE = DomainType.CURVE\n",
    "    INSTANCE = DomainType.INSTANCE\n",
    "    LAYER = DomainType.LAYER\n",
    "\n",
    "@dataclass\n",
    "class AttributeType:\n",
    "    type_name: str\n",
    "    value_name: str\n",
    "    dtype: Type\n",
    "    dimensions: tuple\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.type_name\n",
    "\n",
    "class AttributeTypes(Enum):\n",
    "    FLOAT = AttributeType(\"FLOAT\", \"value\", float, (1,))\n",
    "    FLOAT_VECTOR = AttributeType(\"FLOAT_VECTOR\", \"vector\", float, (3,))\n",
    "    FLOAT2 = AttributeType(\"FLOAT2\", \"vector\", float, (2,))\n",
    "    FLOAT_COLOR = AttributeType(\"FLOAT_COLOR\", \"color\", float, (4,))\n",
    "    BYTE_COLOR = AttributeType(\"BYTE_COLOR\", \"color\", int, (4,))\n",
    "    QUATERNION = AttributeType(\"QUATERNION\", \"value\", float, (4,))\n",
    "    INT = AttributeType(\"INT\", \"value\", int, (1,))\n",
    "    INT8 = AttributeType(\"INT8\", \"value\", int, (1,))\n",
    "    INT32_2D = AttributeType(\"INT32_2D\", \"value\", int, (2,))\n",
    "    FLOAT4X4 = AttributeType(\"FLOAT4X4\", \"matrix\", float, (4, 4))\n",
    "    BOOLEAN = AttributeType(\"BOOLEAN\", \"value\", bool, (1,))\n",
    "\n",
    "def guess_attribute_type(series: pl.Series) -> AttributeType:\n",
    "    dtype = series.dtype\n",
    "    if dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64]:\n",
    "        return AttributeTypes.INT.value\n",
    "    elif dtype in [pl.Float32, pl.Float64]:\n",
    "        return AttributeTypes.FLOAT.value\n",
    "    elif dtype == pl.Boolean:\n",
    "        return AttributeTypes.BOOLEAN.value\n",
    "    elif isinstance(dtype, pl.datatypes.List):\n",
    "        first_valid = None\n",
    "        for val in series:\n",
    "            if val is not None:\n",
    "                first_valid = val\n",
    "                break\n",
    "        if first_valid is not None and isinstance(first_valid, (list, tuple, np.ndarray)):\n",
    "            length = len(first_valid)\n",
    "            if length == 2:\n",
    "                return AttributeTypes.FLOAT2.value\n",
    "            elif length == 3:\n",
    "                return AttributeTypes.FLOAT_VECTOR.value\n",
    "            elif length == 4:\n",
    "                return AttributeTypes.FLOAT_COLOR.value\n",
    "            elif length == 16:\n",
    "                return AttributeTypes.FLOAT4X4.value\n",
    "            else:\n",
    "                return AttributeTypes.FLOAT_VECTOR.value\n",
    "    return AttributeTypes.FLOAT.value\n",
    "\n",
    "class PolarsMesh:\n",
    "    def __init__(self, dataframe: pl.DataFrame, mesh_name: str = \"PointCloudMeshwithAttributes\", object_name: str = \"PointCloudAttributes\"):\n",
    "        self.mesh_name = mesh_name\n",
    "        self.object_name = object_name\n",
    "        self.included_columns = []\n",
    "        self.process_dataframe(dataframe)\n",
    "        self.length = len(self.dataframe)\n",
    "        self.vertices = [(0, 0, 0)] * self.length\n",
    "        self.mesh = bpy.data.meshes.new(self.mesh_name)\n",
    "        self.point_obj = bpy.data.objects.new(self.object_name, self.mesh)\n",
    "        # bpy.context.collection.objects.link(self.point_obj)\n",
    "        self.mesh.from_pydata(self.vertices, [], [])\n",
    "        self.mesh.update()\n",
    "        self.add_attributes()\n",
    "\n",
    "    def process_dataframe(self, dataframe: pl.DataFrame):\n",
    "        included_columns = []\n",
    "        excluded_columns = []\n",
    "        for col, dtype in zip(dataframe.columns, dataframe.dtypes):\n",
    "            if dtype in [pl.Boolean, pl.Float32, pl.Float64, pl.Int8, pl.Int16, pl.Int32, pl.Int64]:\n",
    "                included_columns.append(col)\n",
    "            elif isinstance(dtype, pl.datatypes.List):\n",
    "                first_valid = None\n",
    "                for val in dataframe[col]:\n",
    "                    if val is not None:\n",
    "                        first_valid = val\n",
    "                        break\n",
    "                if first_valid is not None and isinstance(first_valid, (list, tuple, np.ndarray)):\n",
    "                    included_columns.append(col)\n",
    "                else:\n",
    "                    excluded_columns.append(col)\n",
    "            else:\n",
    "                excluded_columns.append(col)\n",
    "        if excluded_columns:\n",
    "            print(f\"Columns not included (unsupported data types): {excluded_columns}\")\n",
    "        self.dataframe = dataframe.select(included_columns)\n",
    "        self.included_columns = included_columns\n",
    "        print(f\"Columns added to the mesh: {included_columns}\")\n",
    "\n",
    "    def add_attributes(self):\n",
    "        for column in self.dataframe.columns:\n",
    "            series = self.dataframe[column]\n",
    "            attr_type = guess_attribute_type(series)\n",
    "            data = self.series_to_numpy(series, attr_type)\n",
    "            self.store_attribute(self.point_obj, data, column, attr_type)\n",
    "\n",
    "    def update(self, dataframe: pl.DataFrame):\n",
    "        previous_columns = set(self.included_columns)\n",
    "        self.process_dataframe(dataframe)\n",
    "        new_length = len(self.dataframe)\n",
    "        if new_length != self.length:\n",
    "            self.length = new_length\n",
    "            self.vertices = [(0, 0, 0)] * self.length\n",
    "            self.mesh.from_pydata(self.vertices, [], [])\n",
    "            self.mesh.update()\n",
    "        for attr_name in previous_columns:\n",
    "            if attr_name in self.mesh.attributes:\n",
    "                self.mesh.attributes.remove(self.mesh.attributes[attr_name])\n",
    "        self.add_attributes()\n",
    "\n",
    "    def clear(self):\n",
    "        self.dataframe = pl.DataFrame()\n",
    "        for attr_name in self.included_columns:\n",
    "            if attr_name in self.mesh.attributes:\n",
    "                self.mesh.attributes.remove(self.mesh.attributes[attr_name])\n",
    "        self.included_columns = []\n",
    "\n",
    "    def store_attribute(self, obj: bpy.types.Object, data: np.ndarray, name: str, attr_type: AttributeType, domain: DomainType = DomainType.POINT):\n",
    "        attributes = obj.data.attributes\n",
    "        if name in attributes:\n",
    "            attribute = attributes[name]\n",
    "        else:\n",
    "            attribute = attributes.new(name, attr_type.type_name, domain.value)\n",
    "        expected_length = len(attribute.data) * int(np.prod(attr_type.dimensions))\n",
    "        if data.size != expected_length:\n",
    "            raise ValueError(f\"Data length {data.size} does not match expected size {expected_length} for attribute '{name}'.\")\n",
    "        attribute.data.foreach_set(attr_type.value_name, data.flatten())\n",
    "\n",
    "    def series_to_numpy(self, series: pl.Series, attr_type: AttributeType) -> np.ndarray:\n",
    "        if attr_type.dimensions == (1,):\n",
    "            return series.to_numpy().astype(attr_type.dtype)\n",
    "        else:\n",
    "            arr = np.array(series.to_list(), dtype=attr_type.dtype)\n",
    "            if arr.ndim == 1:\n",
    "                arr = np.expand_dims(arr, axis=1)\n",
    "            return arr.reshape(-1, int(np.prod(attr_type.dimensions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pl.read_json(\"/Users/jan-hendrik/projects/blender_csv_import/generate_data/dino_star_vectors.json\")\n",
    "# Explode the columns to transform list[list] into individual rows\n",
    "df = df.explode([\"Dino\", \"Star\"])\n",
    "\n",
    "\n",
    "\n",
    "blender_mesh = PolarsMesh(dataframe=df, object_name=f\"JSON OBJ\")\n",
    "\n",
    "# Link the new mesh to the Blender scene\n",
    "bpy.context.collection.objects.link(blender_mesh.point_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_json(\"/Users/jan-hendrik/projects/blender_csv_import/generate_data/dino_star_vectors.json\")\n",
    "# Explode the columns to transform list[list] into individual rows\n",
    "df = df.explode([\"Dino\", \"Star\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Dino\"] [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dino\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Ensure each cell remains as a list\n",
    "df = df.with_columns(\n",
    "    pl.col(\"Dino\").map_elements(lambda x: list(x)).alias(\"Dino\")\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Dino\"] [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
