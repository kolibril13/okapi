{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import bpy\n",
    "#from bl_ext.blender_org.csv_importer import PolarsMesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://github.com/BradyAJohnston/MolecularNodes/blob/80f3dac339750638bb5f5edc3b1e66292fccf642/molecularnodes/bpyd/attribute.py\n",
    "# and this prompt: https://chatgpt.com/share/672de0c6-b18c-8013-84d1-ecf23043c790\n",
    "\n",
    "import bpy\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from dataclasses import dataclass\n",
    "from typing import Type, Any\n",
    "from enum import Enum\n",
    "\n",
    "class DomainType(Enum):\n",
    "    POINT = \"POINT\"\n",
    "    EDGE = \"EDGE\"\n",
    "    FACE = \"FACE\"\n",
    "    CORNER = \"CORNER\"\n",
    "    CURVE = \"CURVE\"\n",
    "    INSTANCE = \"INSTANCE\"\n",
    "    LAYER = \"LAYER\"\n",
    "\n",
    "class Domains:\n",
    "    POINT = DomainType.POINT\n",
    "    EDGE = DomainType.EDGE\n",
    "    FACE = DomainType.FACE\n",
    "    CORNER = DomainType.CORNER\n",
    "    CURVE = DomainType.CURVE\n",
    "    INSTANCE = DomainType.INSTANCE\n",
    "    LAYER = DomainType.LAYER\n",
    "\n",
    "@dataclass\n",
    "class AttributeType:\n",
    "    type_name: str\n",
    "    value_name: str\n",
    "    dtype: Type\n",
    "    dimensions: tuple\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.type_name\n",
    "\n",
    "class AttributeTypes(Enum):\n",
    "    FLOAT = AttributeType(\"FLOAT\", \"value\", float, (1,))\n",
    "    FLOAT_VECTOR = AttributeType(\"FLOAT_VECTOR\", \"vector\", float, (3,))\n",
    "    FLOAT2 = AttributeType(\"FLOAT2\", \"vector\", float, (2,))\n",
    "    FLOAT_COLOR = AttributeType(\"FLOAT_COLOR\", \"color\", float, (4,))\n",
    "    BYTE_COLOR = AttributeType(\"BYTE_COLOR\", \"color\", int, (4,))\n",
    "    QUATERNION = AttributeType(\"QUATERNION\", \"value\", float, (4,))\n",
    "    INT = AttributeType(\"INT\", \"value\", int, (1,))\n",
    "    INT8 = AttributeType(\"INT8\", \"value\", int, (1,))\n",
    "    INT32_2D = AttributeType(\"INT32_2D\", \"value\", int, (2,))\n",
    "    FLOAT4X4 = AttributeType(\"FLOAT4X4\", \"matrix\", float, (4, 4))\n",
    "    BOOLEAN = AttributeType(\"BOOLEAN\", \"value\", bool, (1,))\n",
    "\n",
    "def guess_attribute_type(series: pl.Series) -> AttributeType:\n",
    "    dtype = series.dtype\n",
    "    if dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64]:\n",
    "        return AttributeTypes.INT.value\n",
    "    elif dtype in [pl.Float32, pl.Float64]:\n",
    "        return AttributeTypes.FLOAT.value\n",
    "    elif dtype == pl.Boolean:\n",
    "        return AttributeTypes.BOOLEAN.value\n",
    "    elif isinstance(dtype, pl.datatypes.List):\n",
    "        first_valid = None\n",
    "        for val in series:\n",
    "            if val is not None:\n",
    "                first_valid = val\n",
    "                break\n",
    "        if first_valid is not None and isinstance(first_valid, (list, tuple, np.ndarray)):\n",
    "            length = len(first_valid)\n",
    "            if length == 2:\n",
    "                return AttributeTypes.FLOAT2.value\n",
    "            elif length == 3:\n",
    "                return AttributeTypes.FLOAT_VECTOR.value\n",
    "            elif length == 4:\n",
    "                return AttributeTypes.FLOAT_COLOR.value\n",
    "            elif length == 16:\n",
    "                return AttributeTypes.FLOAT4X4.value\n",
    "            else:\n",
    "                return AttributeTypes.FLOAT_VECTOR.value\n",
    "    return AttributeTypes.FLOAT.value\n",
    "\n",
    "class PolarsMesh:\n",
    "    def __init__(self, dataframe: pl.DataFrame, mesh_name: str = \"PointCloudMeshwithAttributes\", object_name: str = \"PointCloudAttributes\"):\n",
    "        self.mesh_name = mesh_name\n",
    "        self.object_name = object_name\n",
    "        self.included_columns = []\n",
    "        self.process_dataframe(dataframe)\n",
    "        self.length = len(self.dataframe)\n",
    "        self.vertices = [(0, 0, 0)] * self.length\n",
    "        self.mesh = bpy.data.meshes.new(self.mesh_name)\n",
    "        self.point_obj = bpy.data.objects.new(self.object_name, self.mesh)\n",
    "        # bpy.context.collection.objects.link(self.point_obj)\n",
    "        self.mesh.from_pydata(self.vertices, [], [])\n",
    "        self.mesh.update()\n",
    "        self.add_attributes()\n",
    "\n",
    "    def process_dataframe(self, dataframe: pl.DataFrame):\n",
    "        included_columns = []\n",
    "        excluded_columns = []\n",
    "        for col, dtype in zip(dataframe.columns, dataframe.dtypes):\n",
    "            if dtype in [pl.Boolean, pl.Float32, pl.Float64, pl.Int8, pl.Int16, pl.Int32, pl.Int64]:\n",
    "                included_columns.append(col)\n",
    "            elif isinstance(dtype, pl.datatypes.List):\n",
    "                first_valid = None\n",
    "                for val in dataframe[col]:\n",
    "                    if val is not None:\n",
    "                        first_valid = val\n",
    "                        break\n",
    "                if first_valid is not None and isinstance(first_valid, (list, tuple, np.ndarray)):\n",
    "                    included_columns.append(col)\n",
    "                else:\n",
    "                    excluded_columns.append(col)\n",
    "            else:\n",
    "                excluded_columns.append(col)\n",
    "        if excluded_columns:\n",
    "            print(f\"Columns not included (unsupported data types): {excluded_columns}\")\n",
    "        self.dataframe = dataframe.select(included_columns)\n",
    "        self.included_columns = included_columns\n",
    "        print(f\"Columns added to the mesh: {included_columns}\")\n",
    "\n",
    "    def add_attributes(self):\n",
    "        for column in self.dataframe.columns:\n",
    "            series = self.dataframe[column]\n",
    "            attr_type = guess_attribute_type(series)\n",
    "            data = self.series_to_numpy(series, attr_type)\n",
    "            self.store_attribute(self.point_obj, data, column, attr_type)\n",
    "\n",
    "    def update(self, dataframe: pl.DataFrame):\n",
    "        previous_columns = set(self.included_columns)\n",
    "        self.process_dataframe(dataframe)\n",
    "        new_length = len(self.dataframe)\n",
    "        if new_length != self.length:\n",
    "            self.length = new_length\n",
    "            self.vertices = [(0, 0, 0)] * self.length\n",
    "            self.mesh.from_pydata(self.vertices, [], [])\n",
    "            self.mesh.update()\n",
    "        for attr_name in previous_columns:\n",
    "            if attr_name in self.mesh.attributes:\n",
    "                self.mesh.attributes.remove(self.mesh.attributes[attr_name])\n",
    "        self.add_attributes()\n",
    "\n",
    "    def clear(self):\n",
    "        self.dataframe = pl.DataFrame()\n",
    "        for attr_name in self.included_columns:\n",
    "            if attr_name in self.mesh.attributes:\n",
    "                self.mesh.attributes.remove(self.mesh.attributes[attr_name])\n",
    "        self.included_columns = []\n",
    "\n",
    "    def store_attribute(self, obj: bpy.types.Object, data: np.ndarray, name: str, attr_type: AttributeType, domain: DomainType = DomainType.POINT):\n",
    "        attributes = obj.data.attributes\n",
    "        if name in attributes:\n",
    "            attribute = attributes[name]\n",
    "        else:\n",
    "            attribute = attributes.new(name, attr_type.type_name, domain.value)\n",
    "        expected_length = len(attribute.data) * int(np.prod(attr_type.dimensions))\n",
    "        if data.size != expected_length:\n",
    "            raise ValueError(f\"Data length {data.size} does not match expected size {expected_length} for attribute '{name}'.\")\n",
    "        attribute.data.foreach_set(attr_type.value_name, data.flatten())\n",
    "\n",
    "    def series_to_numpy(self, series: pl.Series, attr_type: AttributeType) -> np.ndarray:\n",
    "        if attr_type.dimensions == (1,):\n",
    "            return series.to_numpy().astype(attr_type.dtype)\n",
    "        else:\n",
    "            arr = np.array(series.to_list(), dtype=attr_type.dtype)\n",
    "            if arr.ndim == 1:\n",
    "                arr = np.expand_dims(arr, axis=1)\n",
    "            return arr.reshape(-1, int(np.prod(attr_type.dimensions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns not included (unsupported data types): ['Dino', 'Star']\n",
      "Columns added to the mesh: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the JSON file\n",
    "df = pl.read_json(\"/Users/jan-hendrik/projects/blender_csv_import/generate_data/dino_star_vectors_3d_vector.json\")\n",
    "# Identify columns with list[list] values\n",
    "columns_to_explode = [col for col in df.columns if df[col].dtype == pl.List(pl.List)]\n",
    "# Explode all identified columns\n",
    "df = df.explode(columns_to_explode)\n",
    "\n",
    "blender_mesh = PolarsMesh(dataframe=df, object_name=f\"JSON OBJ\")\n",
    "\n",
    "# Link the new mesh to the Blender scene\n",
    "bpy.context.collection.objects.link(blender_mesh.point_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.series.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"Dino\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns not included (unsupported data types): ['Dino', 'Star']\n",
      "Columns added to the mesh: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import bpy\n",
    "\n",
    "# Read the JSON file\n",
    "df = pl.read_json(\"/Users/jan-hendrik/projects/blender_csv_import/generate_data/dino_star_vectors.json\")\n",
    "\n",
    "# First, explode the nested lists\n",
    "df = df.explode([\"Dino\", \"Star\"])\n",
    "\n",
    "# Convert the lists to proper Series format\n",
    "df = df.with_columns([\n",
    "    pl.col(\"Dino\").map_elements(lambda x: pl.Series(x)).alias(\"Dino\"),\n",
    "    pl.col(\"Star\").map_elements(lambda x: pl.Series(x)).alias(\"Star\")\n",
    "])\n",
    "\n",
    "# Convert every element in each column to a list if it's a polars.Series\n",
    "df = df.with_columns([\n",
    "    pl.col(col).map_elements(lambda x: list(x) if isinstance(x, pl.Series) else x).alias(col)\n",
    "    for col in df.columns\n",
    "])\n",
    "\n",
    "# Create and link the mesh\n",
    "blender_mesh = PolarsMesh(dataframe=df, object_name=\"JSON OBJ\")\n",
    "bpy.context.collection.objects.link(blender_mesh.point_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.series.series.Series"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Read the JSON file\n",
    "df = pl.read_json(\"/Users/jan-hendrik/projects/blender_csv_import/generate_data/dino_star_vectors_3d_vector.json\")\n",
    "# Identify columns with list[list] values\n",
    "columns_to_explode = [col for col in df.columns if df[col].dtype == pl.List(pl.List)]\n",
    "# Explode all identified columns\n",
    "df = df.explode(columns_to_explode)\n",
    "\n",
    "\n",
    "type(df[\"Dino\"] [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (142,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Dino</th></tr><tr><td>list[f64]</td></tr></thead><tbody><tr><td>[55.3846, 97.1795]</td></tr><tr><td>[51.5385, 96.0256]</td></tr><tr><td>[46.1538, 94.4872]</td></tr><tr><td>[42.8205, 91.4103]</td></tr><tr><td>[40.7692, 88.3333]</td></tr><tr><td>&hellip;</td></tr><tr><td>[39.4872, 25.3846]</td></tr><tr><td>[91.2821, 41.5385]</td></tr><tr><td>[50.0, 95.7692]</td></tr><tr><td>[47.9487, 95.0]</td></tr><tr><td>[44.1026, 92.6923]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (142,)\n",
       "Series: 'Dino' [list[f64]]\n",
       "[\n",
       "\t[55.3846, 97.1795]\n",
       "\t[51.5385, 96.0256]\n",
       "\t[46.1538, 94.4872]\n",
       "\t[42.8205, 91.4103]\n",
       "\t[40.7692, 88.3333]\n",
       "\t…\n",
       "\t[39.4872, 25.3846]\n",
       "\t[91.2821, 41.5385]\n",
       "\t[50.0, 95.7692]\n",
       "\t[47.9487, 95.0]\n",
       "\t[44.1026, 92.6923]\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Dino\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (142, 2)\n",
      "┌────────────────────┬────────────────────┐\n",
      "│ Dino               ┆ Star               │\n",
      "│ ---                ┆ ---                │\n",
      "│ list[f64]          ┆ list[f64]          │\n",
      "╞════════════════════╪════════════════════╡\n",
      "│ [55.3846, 97.1795] ┆ [58.2136, 91.8819] │\n",
      "│ [51.5385, 96.0256] ┆ [58.1961, 92.215]  │\n",
      "│ [46.1538, 94.4872] ┆ [58.7182, 90.3105] │\n",
      "│ [42.8205, 91.4103] ┆ [57.2784, 89.9076] │\n",
      "│ [40.7692, 88.3333] ┆ [58.082, 92.0081]  │\n",
      "│ …                  ┆ …                  │\n",
      "│ [39.4872, 25.3846] ┆ [43.7226, 19.0773] │\n",
      "│ [91.2821, 41.5385] ┆ [79.3261, 52.9004] │\n",
      "│ [50.0, 95.7692]    ┆ [56.664, 87.9401]  │\n",
      "│ [47.9487, 95.0]    ┆ [57.8218, 90.6932] │\n",
      "│ [44.1026, 92.6923] ┆ [58.2432, 92.1043] │\n",
      "└────────────────────┴────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/w5m51rrn71db4cvkds08wdg80000gn/T/ipykernel_1174/2906863085.py:4: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df = df.with_columns(\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Ensure each cell remains as a list\n",
    "df = df.with_columns(\n",
    "    pl.col(\"Dino\").map_elements(lambda x: list(x)).alias(\"Dino\")\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Dino\"] [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender",
   "language": "python",
   "name": "blender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
