{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import bpy\n",
    "#from bl_ext.blender_org.csv_importer import PolarsMesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://github.com/BradyAJohnston/MolecularNodes/blob/80f3dac339750638bb5f5edc3b1e66292fccf642/molecularnodes/bpyd/attribute.py\n",
    "# and this prompt: https://chatgpt.com/share/672de0c6-b18c-8013-84d1-ecf23043c790\n",
    "import bpy\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from dataclasses import dataclass\n",
    "from typing import Type, Any\n",
    "from enum import Enum\n",
    "\n",
    "class DomainType(Enum):\n",
    "    POINT = \"POINT\"\n",
    "    EDGE = \"EDGE\"\n",
    "    FACE = \"FACE\"\n",
    "    CORNER = \"CORNER\"\n",
    "    CURVE = \"CURVE\"\n",
    "    INSTANCE = \"INSTANCE\"\n",
    "    LAYER = \"LAYER\"\n",
    "\n",
    "class Domains:\n",
    "    POINT = DomainType.POINT\n",
    "    EDGE = DomainType.EDGE\n",
    "    FACE = DomainType.FACE\n",
    "    CORNER = DomainType.CORNER\n",
    "    CURVE = DomainType.CURVE\n",
    "    INSTANCE = DomainType.INSTANCE\n",
    "    LAYER = DomainType.LAYER\n",
    "\n",
    "@dataclass\n",
    "class AttributeType:\n",
    "    type_name: str\n",
    "    value_name: str\n",
    "    dtype: Type\n",
    "    dimensions: tuple\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.type_name\n",
    "\n",
    "class AttributeTypes(Enum):\n",
    "    FLOAT = AttributeType(\"FLOAT\", \"value\", float, (1,))\n",
    "    FLOAT_VECTOR = AttributeType(\"FLOAT_VECTOR\", \"vector\", float, (3,))\n",
    "    FLOAT2 = AttributeType(\"FLOAT2\", \"vector\", float, (2,))\n",
    "    FLOAT_COLOR = AttributeType(\"FLOAT_COLOR\", \"color\", float, (4,))\n",
    "    BYTE_COLOR = AttributeType(\"BYTE_COLOR\", \"color\", int, (4,))\n",
    "    QUATERNION = AttributeType(\"QUATERNION\", \"value\", float, (4,))\n",
    "    INT = AttributeType(\"INT\", \"value\", int, (1,))\n",
    "    INT8 = AttributeType(\"INT8\", \"value\", int, (1,))\n",
    "    INT32_2D = AttributeType(\"INT32_2D\", \"value\", int, (2,))\n",
    "    FLOAT4X4 = AttributeType(\"FLOAT4X4\", \"matrix\", float, (4, 4))\n",
    "    BOOLEAN = AttributeType(\"BOOLEAN\", \"value\", bool, (1,))\n",
    "\n",
    "def guess_attribute_type(series: pl.Series) -> AttributeType:\n",
    "    print(f\"[DEBUG guess_attribute_type] Start: {series.name}, dtype={series.dtype}\")\n",
    "    dtype = series.dtype\n",
    "    if dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64]:\n",
    "        print(\"[DEBUG guess_attribute_type] Detected INT type\")\n",
    "        return AttributeTypes.INT.value\n",
    "    elif dtype in [pl.Float32, pl.Float64]:\n",
    "        print(\"[DEBUG guess_attribute_type] Detected FLOAT type\")\n",
    "        return AttributeTypes.FLOAT.value\n",
    "    elif dtype == pl.Boolean:\n",
    "        print(\"[DEBUG guess_attribute_type] Detected BOOLEAN type\")\n",
    "        return AttributeTypes.BOOLEAN.value\n",
    "    elif isinstance(dtype, pl.datatypes.List):\n",
    "        print(\"[DEBUG guess_attribute_type] dtype is a LIST, checking first valid entry\")\n",
    "        first_valid = None\n",
    "        for val in series:\n",
    "            if val is not None:\n",
    "                first_valid = val\n",
    "                break\n",
    "        print(f\"[DEBUG guess_attribute_type] First valid in list: {first_valid}\")\n",
    "        if first_valid is not None:\n",
    "            # If the first_valid is a pl.Series, handle similarly to object columns\n",
    "            if isinstance(first_valid, pl.Series):\n",
    "                length = len(first_valid)\n",
    "                print(f\"[DEBUG guess_attribute_type] Detected Series in list with length {length}\")\n",
    "                if length == 2:\n",
    "                    return AttributeTypes.FLOAT2.value\n",
    "                elif length == 3:\n",
    "                    return AttributeTypes.FLOAT_VECTOR.value\n",
    "                elif length == 4:\n",
    "                    return AttributeTypes.FLOAT_COLOR.value\n",
    "                elif length == 16:\n",
    "                    return AttributeTypes.FLOAT4X4.value\n",
    "                else:\n",
    "                    print(\"[DEBUG guess_attribute_type] Unsupported length for series type in list, falling back to FLOAT_VECTOR\")\n",
    "                    return AttributeTypes.FLOAT_VECTOR.value\n",
    "            # Else assume a numeric list\n",
    "            elif isinstance(first_valid, (list, tuple, np.ndarray)):\n",
    "                length = len(first_valid)\n",
    "                print(f\"[DEBUG guess_attribute_type] Length of first_valid numeric list: {length}\")\n",
    "                if length == 2:\n",
    "                    return AttributeTypes.FLOAT2.value\n",
    "                elif length == 3:\n",
    "                    return AttributeTypes.FLOAT_VECTOR.value\n",
    "                elif length == 4:\n",
    "                    return AttributeTypes.FLOAT_COLOR.value\n",
    "                elif length == 16:\n",
    "                    return AttributeTypes.FLOAT4X4.value\n",
    "                else:\n",
    "                    print(\"[DEBUG guess_attribute_type] Unsupported length for numeric list, falling back to FLOAT_VECTOR\")\n",
    "                    return AttributeTypes.FLOAT_VECTOR.value\n",
    "    elif dtype == pl.Object:\n",
    "        print(\"[DEBUG guess_attribute_type] dtype is OBJECT, checking for pl.Series in cells\")\n",
    "        first_valid = None\n",
    "        for val in series:\n",
    "            if val is not None:\n",
    "                first_valid = val\n",
    "                break\n",
    "        print(f\"[DEBUG guess_attribute_type] First valid in object column: {first_valid}\")\n",
    "        if first_valid is not None and isinstance(first_valid, pl.Series):\n",
    "            length = len(first_valid)\n",
    "            print(f\"[DEBUG guess_attribute_type] Detected Series in cells with length {length}\")\n",
    "            if length == 2:\n",
    "                return AttributeTypes.FLOAT2.value\n",
    "            elif length == 3:\n",
    "                return AttributeTypes.FLOAT_VECTOR.value\n",
    "            elif length == 4:\n",
    "                return AttributeTypes.FLOAT_COLOR.value\n",
    "            elif length == 16:\n",
    "                return AttributeTypes.FLOAT4X4.value\n",
    "            else:\n",
    "                print(\"[DEBUG guess_attribute_type] Unsupported length for series type, falling back to FLOAT_VECTOR\")\n",
    "                return AttributeTypes.FLOAT_VECTOR.value\n",
    "    # Default fallback\n",
    "    print(\"[DEBUG guess_attribute_type] Fallback to FLOAT\")\n",
    "    return AttributeTypes.FLOAT.value\n",
    "\n",
    "class PolarsMesh:\n",
    "    def __init__(self, dataframe: pl.DataFrame, mesh_name: str = \"PointCloudMeshwithAttributes\", object_name: str = \"PointCloudAttributes\"):\n",
    "        print(\"[DEBUG PolarsMesh.__init__] Initializing PolarsMesh\")\n",
    "        self.mesh_name = mesh_name\n",
    "        self.object_name = object_name\n",
    "        self.included_columns = []\n",
    "        self.process_dataframe(dataframe)\n",
    "        self.length = len(self.dataframe)\n",
    "        print(f\"[DEBUG PolarsMesh.__init__] Length of dataframe: {self.length}\")\n",
    "        self.vertices = [(0, 0, 0)] * self.length\n",
    "        self.mesh = bpy.data.meshes.new(self.mesh_name)\n",
    "        self.point_obj = bpy.data.objects.new(self.object_name, self.mesh)\n",
    "        print(\"[DEBUG PolarsMesh.__init__] Created mesh and object\")\n",
    "        # Uncomment if running in Blender\n",
    "        # bpy.context.collection.objects.link(self.point_obj)\n",
    "        print(\"[DEBUG PolarsMesh.__init__] Creating mesh from pydata\")\n",
    "        self.mesh.from_pydata(self.vertices, [], [])\n",
    "        self.mesh.update()\n",
    "        print(\"[DEBUG PolarsMesh.__init__] Mesh updated, adding attributes\")\n",
    "        self.add_attributes()\n",
    "\n",
    "    def process_dataframe(self, dataframe: pl.DataFrame):\n",
    "        print(\"[DEBUG process_dataframe] Processing dataframe\")\n",
    "        included_columns = []\n",
    "        excluded_columns = []\n",
    "        for col, dtype in zip(dataframe.columns, dataframe.dtypes):\n",
    "            print(f\"[DEBUG process_dataframe] Checking column: {col}, dtype={dtype}\")\n",
    "            if dtype in [pl.Boolean, pl.Float32, pl.Float64, pl.Int8, pl.Int16, pl.Int32, pl.Int64]:\n",
    "                included_columns.append(col)\n",
    "            elif isinstance(dtype, pl.datatypes.List):\n",
    "                print(\"[DEBUG process_dataframe] Column is list type, checking first valid\")\n",
    "                first_valid = None\n",
    "                for val in dataframe[col]:\n",
    "                    if val is not None:\n",
    "                        first_valid = val\n",
    "                        break\n",
    "                print(f\"[DEBUG process_dataframe] first_valid: {first_valid}\")\n",
    "                if first_valid is not None:\n",
    "                    if isinstance(first_valid, pl.Series):\n",
    "                        # Check that all are either None or Series of the same length\n",
    "                        length = len(first_valid)\n",
    "                        if all((isinstance(v, pl.Series) and len(v) == length) or v is None for v in dataframe[col]):\n",
    "                            included_columns.append(col)\n",
    "                        else:\n",
    "                            excluded_columns.append(col)\n",
    "                    elif isinstance(first_valid, (list, tuple, np.ndarray)):\n",
    "                        # Numeric lists\n",
    "                        included_columns.append(col)\n",
    "                    else:\n",
    "                        excluded_columns.append(col)\n",
    "                else:\n",
    "                    excluded_columns.append(col)\n",
    "            elif dtype == pl.Object:\n",
    "                print(\"[DEBUG process_dataframe] Column is object type, checking for pl.Series in cells\")\n",
    "                first_valid = None\n",
    "                for val in dataframe[col]:\n",
    "                    if val is not None:\n",
    "                        first_valid = val\n",
    "                        break\n",
    "                print(f\"[DEBUG process_dataframe] first_valid: {first_valid}\")\n",
    "                if first_valid is not None and isinstance(first_valid, pl.Series):\n",
    "                    length = len(first_valid)\n",
    "                    print(f\"[DEBUG process_dataframe] First valid series length: {length}\")\n",
    "                    if all((isinstance(v, pl.Series) and len(v) == length) or v is None for v in dataframe[col]):\n",
    "                        included_columns.append(col)\n",
    "                    else:\n",
    "                        excluded_columns.append(col)\n",
    "                else:\n",
    "                    excluded_columns.append(col)\n",
    "            else:\n",
    "                excluded_columns.append(col)\n",
    "\n",
    "        if excluded_columns:\n",
    "            print(f\"Columns not included (unsupported data types): {excluded_columns}\")\n",
    "        self.dataframe = dataframe.select(included_columns)\n",
    "        self.included_columns = included_columns\n",
    "        print(f\"[DEBUG process_dataframe] Columns added to the mesh: {included_columns}\")\n",
    "\n",
    "    def add_attributes(self):\n",
    "        print(\"[DEBUG add_attributes] Adding attributes for included columns\")\n",
    "        for column in self.dataframe.columns:\n",
    "            print(f\"[DEBUG add_attributes] Processing column: {column}\")\n",
    "            series = self.dataframe[column]\n",
    "            attr_type = guess_attribute_type(series)\n",
    "            print(f\"[DEBUG add_attributes] Attribute type guessed: {attr_type.type_name}\")\n",
    "            data = self.series_to_numpy(series, attr_type)\n",
    "            print(f\"[DEBUG add_attributes] Data shape after conversion: {data.shape}\")\n",
    "            self.store_attribute(self.point_obj, data, column, attr_type)\n",
    "\n",
    "    def update(self, dataframe: pl.DataFrame):\n",
    "        print(\"[DEBUG update] Updating with new dataframe\")\n",
    "        previous_columns = set(self.included_columns)\n",
    "        self.process_dataframe(dataframe)\n",
    "        new_length = len(self.dataframe)\n",
    "        if new_length != self.length:\n",
    "            print(f\"[DEBUG update] Dataframe length changed from {self.length} to {new_length}, updating mesh vertices.\")\n",
    "            self.length = new_length\n",
    "            self.vertices = [(0, 0, 0)] * self.length\n",
    "            self.mesh.from_pydata(self.vertices, [], [])\n",
    "            self.mesh.update()\n",
    "\n",
    "        # Remove previous attributes\n",
    "        for attr_name in previous_columns:\n",
    "            print(f\"[DEBUG update] Removing old attribute: {attr_name}\")\n",
    "            if attr_name in self.mesh.attributes:\n",
    "                self.mesh.attributes.remove(self.mesh.attributes[attr_name])\n",
    "\n",
    "        # Add new attributes\n",
    "        print(\"[DEBUG update] Adding new attributes\")\n",
    "        self.add_attributes()\n",
    "\n",
    "    def clear(self):\n",
    "        print(\"[DEBUG clear] Clearing all attributes\")\n",
    "        self.dataframe = pl.DataFrame()\n",
    "        for attr_name in self.included_columns:\n",
    "            print(f\"[DEBUG clear] Removing attribute: {attr_name}\")\n",
    "            if attr_name in self.mesh.attributes:\n",
    "                self.mesh.attributes.remove(self.mesh.attributes[attr_name])\n",
    "        self.included_columns = []\n",
    "\n",
    "    def store_attribute(self, obj: bpy.types.Object, data: np.ndarray, name: str, attr_type: AttributeType, domain: DomainType = DomainType.POINT):\n",
    "        print(f\"[DEBUG store_attribute] Storing attribute '{name}' with type '{attr_type.type_name}' and domain '{domain.value}'\")\n",
    "        attributes = obj.data.attributes\n",
    "        if name in attributes:\n",
    "            attribute = attributes[name]\n",
    "            print(f\"[DEBUG store_attribute] Attribute '{name}' already exists, reusing it.\")\n",
    "        else:\n",
    "            attribute = attributes.new(name, attr_type.type_name, domain.value)\n",
    "            print(f\"[DEBUG store_attribute] Created new attribute '{name}'\")\n",
    "\n",
    "        expected_length = len(attribute.data) * int(np.prod(attr_type.dimensions))\n",
    "        print(f\"[DEBUG store_attribute] expected_length={expected_length}, data.size={data.size}\")\n",
    "        if data.size != expected_length:\n",
    "            raise ValueError(f\"Data length {data.size} does not match expected size {expected_length} for attribute '{name}'.\")\n",
    "        attribute.data.foreach_set(attr_type.value_name, data.flatten())\n",
    "        print(f\"[DEBUG store_attribute] Finished setting data for attribute '{name}'\")\n",
    "\n",
    "    def series_to_numpy(self, series: pl.Series, attr_type: AttributeType) -> np.ndarray:\n",
    "        print(f\"[DEBUG series_to_numpy] Converting series '{series.name}' to numpy for attribute type '{attr_type.type_name}'\")\n",
    "        # Handle simple scalar attributes\n",
    "        if attr_type.dimensions == (1,):\n",
    "            arr = series.to_numpy().astype(attr_type.dtype)\n",
    "            print(f\"[DEBUG series_to_numpy] Scalar attribute, arr.shape={arr.shape}\")\n",
    "            return arr\n",
    "\n",
    "        # Handle lists or series of arrays\n",
    "        if isinstance(series.dtype, pl.datatypes.List):\n",
    "            # The column might be lists of either numeric arrays or pl.Series\n",
    "            arr_list = []\n",
    "            for val in series:\n",
    "                if val is None:\n",
    "                    arr_list.append(np.zeros(attr_type.dimensions, dtype=attr_type.dtype))\n",
    "                elif isinstance(val, pl.Series):\n",
    "                    arr_list.append(val.to_numpy())\n",
    "                else:\n",
    "                    arr_list.append(np.array(val, dtype=attr_type.dtype))\n",
    "            arr = np.array(arr_list, dtype=attr_type.dtype)\n",
    "            print(f\"[DEBUG series_to_numpy] LIST column converted, arr.shape={arr.shape}\")\n",
    "        elif series.dtype == pl.Object:\n",
    "            print(\"[DEBUG series_to_numpy] Column is OBJECT, converting from pl.Series in each cell\")\n",
    "            arr_list = []\n",
    "            for val in series:\n",
    "                if val is not None:\n",
    "                    val_arr = val.to_numpy()\n",
    "                    arr_list.append(val_arr)\n",
    "                else:\n",
    "                    # If there are missing values\n",
    "                    arr_list.append(np.zeros(attr_type.dimensions, dtype=attr_type.dtype))\n",
    "            arr = np.array(arr_list, dtype=attr_type.dtype)\n",
    "            print(f\"[DEBUG series_to_numpy] OBJECT column converted, arr.shape={arr.shape}\")\n",
    "        else:\n",
    "            # dtype is likely a numeric list\n",
    "            print(\"[DEBUG series_to_numpy] Column is numeric LIST or vector-like, using to_list()\")\n",
    "            arr = np.array(series.to_list(), dtype=attr_type.dtype)\n",
    "            print(f\"[DEBUG series_to_numpy] arr.shape before reshape={arr.shape}\")\n",
    "\n",
    "        if arr.ndim == 1:\n",
    "            print(\"[DEBUG series_to_numpy] Expanding dimensions since arr.ndim=1\")\n",
    "            arr = np.expand_dims(arr, axis=1)\n",
    "\n",
    "        final_shape = (-1, int(np.prod(attr_type.dimensions)))\n",
    "        arr = arr.reshape(final_shape)\n",
    "        print(f\"[DEBUG series_to_numpy] Final arr.shape={arr.shape}\")\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG PolarsMesh.__init__] Initializing PolarsMesh\n",
      "[DEBUG process_dataframe] Processing dataframe\n",
      "[DEBUG process_dataframe] Checking column: Dino, dtype=List(Float64)\n",
      "[DEBUG process_dataframe] Column is list type, checking first valid\n",
      "[DEBUG process_dataframe] first_valid: shape: (3,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t55.3846\n",
      "\t97.1795\n",
      "\t0.0\n",
      "]\n",
      "[DEBUG process_dataframe] Checking column: Star, dtype=List(Float64)\n",
      "[DEBUG process_dataframe] Column is list type, checking first valid\n",
      "[DEBUG process_dataframe] first_valid: shape: (3,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t58.2136\n",
      "\t91.8819\n",
      "\t0.0\n",
      "]\n",
      "[DEBUG process_dataframe] Columns added to the mesh: ['Dino', 'Star']\n",
      "[DEBUG PolarsMesh.__init__] Length of dataframe: 142\n",
      "[DEBUG PolarsMesh.__init__] Created mesh and object\n",
      "[DEBUG PolarsMesh.__init__] Creating mesh from pydata\n",
      "[DEBUG PolarsMesh.__init__] Mesh updated, adding attributes\n",
      "[DEBUG add_attributes] Adding attributes for included columns\n",
      "[DEBUG add_attributes] Processing column: Dino\n",
      "[DEBUG guess_attribute_type] Start: Dino, dtype=List(Float64)\n",
      "[DEBUG guess_attribute_type] dtype is a LIST, checking first valid entry\n",
      "[DEBUG guess_attribute_type] First valid in list: shape: (3,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t55.3846\n",
      "\t97.1795\n",
      "\t0.0\n",
      "]\n",
      "[DEBUG guess_attribute_type] Detected Series in list with length 3\n",
      "[DEBUG add_attributes] Attribute type guessed: FLOAT_VECTOR\n",
      "[DEBUG series_to_numpy] Converting series 'Dino' to numpy for attribute type 'FLOAT_VECTOR'\n",
      "[DEBUG series_to_numpy] LIST column converted, arr.shape=(142, 3)\n",
      "[DEBUG series_to_numpy] Final arr.shape=(142, 3)\n",
      "[DEBUG add_attributes] Data shape after conversion: (142, 3)\n",
      "[DEBUG store_attribute] Storing attribute 'Dino' with type 'FLOAT_VECTOR' and domain 'POINT'\n",
      "[DEBUG store_attribute] Created new attribute 'Dino'\n",
      "[DEBUG store_attribute] expected_length=426, data.size=426\n",
      "[DEBUG store_attribute] Finished setting data for attribute 'Dino'\n",
      "[DEBUG add_attributes] Processing column: Star\n",
      "[DEBUG guess_attribute_type] Start: Star, dtype=List(Float64)\n",
      "[DEBUG guess_attribute_type] dtype is a LIST, checking first valid entry\n",
      "[DEBUG guess_attribute_type] First valid in list: shape: (3,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t58.2136\n",
      "\t91.8819\n",
      "\t0.0\n",
      "]\n",
      "[DEBUG guess_attribute_type] Detected Series in list with length 3\n",
      "[DEBUG add_attributes] Attribute type guessed: FLOAT_VECTOR\n",
      "[DEBUG series_to_numpy] Converting series 'Star' to numpy for attribute type 'FLOAT_VECTOR'\n",
      "[DEBUG series_to_numpy] LIST column converted, arr.shape=(142, 3)\n",
      "[DEBUG series_to_numpy] Final arr.shape=(142, 3)\n",
      "[DEBUG add_attributes] Data shape after conversion: (142, 3)\n",
      "[DEBUG store_attribute] Storing attribute 'Star' with type 'FLOAT_VECTOR' and domain 'POINT'\n",
      "[DEBUG store_attribute] Created new attribute 'Star'\n",
      "[DEBUG store_attribute] expected_length=426, data.size=426\n",
      "[DEBUG store_attribute] Finished setting data for attribute 'Star'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the JSON file\n",
    "df = pl.read_json(\"/Users/jan-hendrik/projects/blender_csv_import/generate_data/dino_star_vectors_3d_vector.json\")\n",
    "# Identify columns with list[list] values\n",
    "columns_to_explode = [col for col in df.columns if df[col].dtype == pl.List(pl.List)]\n",
    "# Explode all identified columns\n",
    "df = df.explode(columns_to_explode)\n",
    "\n",
    "blender_mesh = PolarsMesh(dataframe=df, object_name=f\"JSON OBJ\")\n",
    "\n",
    "# Link the new mesh to the Blender scene\n",
    "bpy.context.collection.objects.link(blender_mesh.point_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Dino</th><th>Star</th></tr><tr><td>list[list[f64]]</td><td>list[list[f64]]</td></tr></thead><tbody><tr><td>[[55.3846, 97.1795], [51.5385, 96.0256], … [44.1026, 92.6923]]</td><td>[[58.2136, 91.8819], [58.1961, 92.215], … [58.2432, 92.1043]]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ Dino                            ┆ Star                            │\n",
       "│ ---                             ┆ ---                             │\n",
       "│ list[list[f64]]                 ┆ list[list[f64]]                 │\n",
       "╞═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ [[55.3846, 97.1795], [51.5385,… ┆ [[58.2136, 91.8819], [58.1961,… │\n",
       "└─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG PolarsMesh.__init__] Initializing PolarsMesh\n",
      "[DEBUG process_dataframe] Processing dataframe\n",
      "[DEBUG process_dataframe] Checking column: Dino, dtype=List(Float64)\n",
      "[DEBUG process_dataframe] Column is list type, checking first valid\n",
      "[DEBUG process_dataframe] first_valid: shape: (2,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t55.3846\n",
      "\t97.1795\n",
      "]\n",
      "[DEBUG process_dataframe] Checking column: Star, dtype=List(Float64)\n",
      "[DEBUG process_dataframe] Column is list type, checking first valid\n",
      "[DEBUG process_dataframe] first_valid: shape: (2,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t58.2136\n",
      "\t91.8819\n",
      "]\n",
      "[DEBUG process_dataframe] Columns added to the mesh: ['Dino', 'Star']\n",
      "[DEBUG PolarsMesh.__init__] Length of dataframe: 142\n",
      "[DEBUG PolarsMesh.__init__] Created mesh and object\n",
      "[DEBUG PolarsMesh.__init__] Creating mesh from pydata\n",
      "[DEBUG PolarsMesh.__init__] Mesh updated, adding attributes\n",
      "[DEBUG add_attributes] Adding attributes for included columns\n",
      "[DEBUG add_attributes] Processing column: Dino\n",
      "[DEBUG guess_attribute_type] Start: Dino, dtype=List(Float64)\n",
      "[DEBUG guess_attribute_type] dtype is a LIST, checking first valid entry\n",
      "[DEBUG guess_attribute_type] First valid in list: shape: (2,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t55.3846\n",
      "\t97.1795\n",
      "]\n",
      "[DEBUG guess_attribute_type] Detected Series in list with length 2\n",
      "[DEBUG add_attributes] Attribute type guessed: FLOAT2\n",
      "[DEBUG series_to_numpy] Converting series 'Dino' to numpy for attribute type 'FLOAT2'\n",
      "[DEBUG series_to_numpy] LIST column converted, arr.shape=(142, 2)\n",
      "[DEBUG series_to_numpy] Final arr.shape=(142, 2)\n",
      "[DEBUG add_attributes] Data shape after conversion: (142, 2)\n",
      "[DEBUG store_attribute] Storing attribute 'Dino' with type 'FLOAT2' and domain 'POINT'\n",
      "[DEBUG store_attribute] Created new attribute 'Dino'\n",
      "[DEBUG store_attribute] expected_length=284, data.size=284\n",
      "[DEBUG store_attribute] Finished setting data for attribute 'Dino'\n",
      "[DEBUG add_attributes] Processing column: Star\n",
      "[DEBUG guess_attribute_type] Start: Star, dtype=List(Float64)\n",
      "[DEBUG guess_attribute_type] dtype is a LIST, checking first valid entry\n",
      "[DEBUG guess_attribute_type] First valid in list: shape: (2,)\n",
      "Series: '' [f64]\n",
      "[\n",
      "\t58.2136\n",
      "\t91.8819\n",
      "]\n",
      "[DEBUG guess_attribute_type] Detected Series in list with length 2\n",
      "[DEBUG add_attributes] Attribute type guessed: FLOAT2\n",
      "[DEBUG series_to_numpy] Converting series 'Star' to numpy for attribute type 'FLOAT2'\n",
      "[DEBUG series_to_numpy] LIST column converted, arr.shape=(142, 2)\n",
      "[DEBUG series_to_numpy] Final arr.shape=(142, 2)\n",
      "[DEBUG add_attributes] Data shape after conversion: (142, 2)\n",
      "[DEBUG store_attribute] Storing attribute 'Star' with type 'FLOAT2' and domain 'POINT'\n",
      "[DEBUG store_attribute] Created new attribute 'Star'\n",
      "[DEBUG store_attribute] expected_length=284, data.size=284\n",
      "[DEBUG store_attribute] Finished setting data for attribute 'Star'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import bpy\n",
    "\n",
    "# Read the JSON file\n",
    "df = pl.read_json(\"/Users/jan-hendrik/projects/blender_csv_import/generate_data/dino_star_vectors.json\")\n",
    "\n",
    "# First, explode the nested lists\n",
    "df = df.explode([\"Dino\", \"Star\"])\n",
    "\n",
    "# Convert the lists to proper Series format\n",
    "df = df.with_columns([\n",
    "    pl.col(\"Dino\").map_elements(lambda x: pl.Series(x)).alias(\"Dino\"),\n",
    "    pl.col(\"Star\").map_elements(lambda x: pl.Series(x)).alias(\"Star\")\n",
    "])\n",
    "\n",
    "# Create and link the mesh\n",
    "blender_mesh = PolarsMesh(dataframe=df, object_name=\"JSON OBJ\")\n",
    "bpy.context.collection.objects.link(blender_mesh.point_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.series.series.Series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"Dino\"] [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (142,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Dino</th></tr><tr><td>list[f64]</td></tr></thead><tbody><tr><td>[55.3846, 97.1795]</td></tr><tr><td>[51.5385, 96.0256]</td></tr><tr><td>[46.1538, 94.4872]</td></tr><tr><td>[42.8205, 91.4103]</td></tr><tr><td>[40.7692, 88.3333]</td></tr><tr><td>&hellip;</td></tr><tr><td>[39.4872, 25.3846]</td></tr><tr><td>[91.2821, 41.5385]</td></tr><tr><td>[50.0, 95.7692]</td></tr><tr><td>[47.9487, 95.0]</td></tr><tr><td>[44.1026, 92.6923]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (142,)\n",
       "Series: 'Dino' [list[f64]]\n",
       "[\n",
       "\t[55.3846, 97.1795]\n",
       "\t[51.5385, 96.0256]\n",
       "\t[46.1538, 94.4872]\n",
       "\t[42.8205, 91.4103]\n",
       "\t[40.7692, 88.3333]\n",
       "\t…\n",
       "\t[39.4872, 25.3846]\n",
       "\t[91.2821, 41.5385]\n",
       "\t[50.0, 95.7692]\n",
       "\t[47.9487, 95.0]\n",
       "\t[44.1026, 92.6923]\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Dino\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (142, 2)\n",
      "┌────────────────────┬────────────────────┐\n",
      "│ Dino               ┆ Star               │\n",
      "│ ---                ┆ ---                │\n",
      "│ list[f64]          ┆ list[f64]          │\n",
      "╞════════════════════╪════════════════════╡\n",
      "│ [55.3846, 97.1795] ┆ [58.2136, 91.8819] │\n",
      "│ [51.5385, 96.0256] ┆ [58.1961, 92.215]  │\n",
      "│ [46.1538, 94.4872] ┆ [58.7182, 90.3105] │\n",
      "│ [42.8205, 91.4103] ┆ [57.2784, 89.9076] │\n",
      "│ [40.7692, 88.3333] ┆ [58.082, 92.0081]  │\n",
      "│ …                  ┆ …                  │\n",
      "│ [39.4872, 25.3846] ┆ [43.7226, 19.0773] │\n",
      "│ [91.2821, 41.5385] ┆ [79.3261, 52.9004] │\n",
      "│ [50.0, 95.7692]    ┆ [56.664, 87.9401]  │\n",
      "│ [47.9487, 95.0]    ┆ [57.8218, 90.6932] │\n",
      "│ [44.1026, 92.6923] ┆ [58.2432, 92.1043] │\n",
      "└────────────────────┴────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/w5m51rrn71db4cvkds08wdg80000gn/T/ipykernel_1174/2906863085.py:4: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df = df.with_columns(\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Ensure each cell remains as a list\n",
    "df = df.with_columns(\n",
    "    pl.col(\"Dino\").map_elements(lambda x: list(x)).alias(\"Dino\")\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Dino\"] [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender",
   "language": "python",
   "name": "blender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
